{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "discrete-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-difference",
   "metadata": {},
   "source": [
    "following implementation discussed here: <https://towardsdatascience.com/implementing-tabnet-in-pytorch-fc977c383279>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "constant-mattress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# following implementation discussed here: <https://towardsdatascience.com/implementing-tabnet-in-pytorch-fc977c383279>\n",
    "\n",
    "# ghost batch norm\n",
    "class GhostBatchNorm(nn.Module):\n",
    "    def __init__(self, input_dim, vbs=64, momentum=0.01):\n",
    "        '''\n",
    "        Arguments:\n",
    "          vbs (int): (optional, Default=128) virtual batch size. Must be\n",
    "            smaller than n_samples in mini-batch\n",
    "          \n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.BN = nn.BatchNorm1d(input_dim, momentum=momentum)\n",
    "        self.vbs = vbs\n",
    "        \n",
    "    def forward(self, x):\n",
    "        chunk = torch.chunk(x, x.size(0) // self.vbs, 0)\n",
    "        res = [self.BN(x_sub) for x_sub in chunk]\n",
    "        return torch.cat(res,0)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-recorder",
   "metadata": {},
   "source": [
    "implementation of SparseMax\n",
    "- REF: https://github.com/aced125/sparsemax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "funky-shanghai",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of SparseMax\n",
    "# REF: https://github.com/aced125/sparsemax\n",
    "\n",
    "def flatten_all_but_nth_dim(ctx, x: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Flattens tensor in all but 1 chosen dimension.\n",
    "    Saves necessary context for backward pass and unflattening.\n",
    "    \"\"\"\n",
    "\n",
    "    # transpose batch and nth dim\n",
    "    x = x.transpose(0, ctx.dim)\n",
    "\n",
    "    # Get and save original size in context for backward pass\n",
    "    original_size = x.size()\n",
    "    ctx.original_size = original_size\n",
    "\n",
    "    # Flatten all dimensions except nth dim\n",
    "    x = x.reshape(x.size(0), -1)\n",
    "\n",
    "    # Transpose flattened dimensions to 0th dim, nth dim to last dim\n",
    "    return ctx, x.transpose(0, -1)\n",
    "\n",
    "\n",
    "def unflatten_all_but_nth_dim(ctx, x: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Unflattens tensor using necessary context\n",
    "    \"\"\"\n",
    "    # Tranpose flattened dim to last dim, nth dim to 0th dim\n",
    "    x = x.transpose(0, 1)\n",
    "\n",
    "    # Reshape to original size\n",
    "    x = x.reshape(ctx.original_size)\n",
    "\n",
    "    # Swap batch dim and nth dim\n",
    "    return ctx, x.transpose(0, ctx.dim)\n",
    "\n",
    "class Sparsemax(nn.Module):\n",
    "    __constants__ = [\"dim\"]\n",
    "\n",
    "    def __init__(self, dim=-1):\n",
    "        \"\"\"\n",
    "        Sparsemax class as seen in https://arxiv.org/pdf/1602.02068.pdf\n",
    "        Parameters\n",
    "        ----------\n",
    "        dim: The dimension we want to cast the operation over. Default -1\n",
    "        \"\"\"\n",
    "        super(Sparsemax, self).__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        self.__dict__.update(state)\n",
    "        if not hasattr(self, \"dim\"):\n",
    "            self.dim = None\n",
    "\n",
    "    def forward(self, input):\n",
    "        return SparsemaxFunction.apply(input, self.dim)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return f\"dim={self.dim}\"\n",
    "\n",
    "\n",
    "class SparsemaxFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input: torch.Tensor, dim: int = -1):\n",
    "        input_dim = input.dim()\n",
    "        if input_dim <= dim or dim < -input_dim:\n",
    "            raise IndexError(\n",
    "                f\"Dimension out of range (expected to be in range of [-{input_dim}, {input_dim - 1}], but got {dim})\"\n",
    "            )\n",
    "\n",
    "        # Save operating dimension to context\n",
    "        ctx.needs_reshaping = input_dim > 2\n",
    "        ctx.dim = dim\n",
    "\n",
    "        if ctx.needs_reshaping:\n",
    "            ctx, input = flatten_all_but_nth_dim(ctx, input)\n",
    "\n",
    "        # Translate by max for numerical stability\n",
    "        input = input - input.max(-1, keepdim=True).values.expand_as(input)\n",
    "\n",
    "        zs = input.sort(-1, descending=True).values\n",
    "        range = torch.arange(1, input.size()[-1] + 1)\n",
    "        range = range.expand_as(input).to(input)\n",
    "\n",
    "        # Determine sparsity of projection\n",
    "        bound = 1 + range * zs\n",
    "        is_gt = bound.gt(zs.cumsum(-1)).type(input.dtype)\n",
    "        k = (is_gt * range).max(-1, keepdim=True).values\n",
    "\n",
    "        # Compute threshold\n",
    "        zs_sparse = is_gt * zs\n",
    "\n",
    "        # Compute taus\n",
    "        taus = (zs_sparse.sum(-1, keepdim=True) - 1) / k\n",
    "        taus = taus.expand_as(input)\n",
    "\n",
    "        output = torch.max(torch.zeros_like(input), input - taus)\n",
    "\n",
    "        # Save context\n",
    "        ctx.save_for_backward(output)\n",
    "\n",
    "        # Reshape back to original shape\n",
    "        if ctx.needs_reshaping:\n",
    "            ctx, output = unflatten_all_but_nth_dim(ctx, output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output, *_ = ctx.saved_tensors\n",
    "\n",
    "        # Reshape if needed\n",
    "        if ctx.needs_reshaping:\n",
    "            ctx, grad_output = flatten_all_but_nth_dim(ctx, grad_output)\n",
    "\n",
    "        # Compute gradient\n",
    "        nonzeros = torch.ne(output, 0)\n",
    "        num_nonzeros = nonzeros.sum(-1, keepdim=True)\n",
    "        sum = (grad_output * nonzeros).sum(-1, keepdim=True) / num_nonzeros\n",
    "        grad_input = nonzeros * (grad_output - sum.expand_as(grad_output))\n",
    "\n",
    "        # Reshape back to original shape\n",
    "        if ctx.needs_reshaping:\n",
    "            ctx, grad_input = unflatten_all_but_nth_dim(ctx, grad_input)\n",
    "\n",
    "        return grad_input, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "based-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (mask*torch.log(mask+1e-10)).mean() #F(x)= -âˆ‘xlog(x+eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "reflected-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnTransformer(nn.Module):\n",
    "    def __init__(self, d_a, inp_dim, relax, vbs=64):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(d_a, inp_dim)\n",
    "        self.BN = GhostBatchNorm(inp_dim, vbs=vbs) # instead of inp_idm, out_dim? otherwise, error in the medium post\n",
    "        self.sparsemax = Sparsemax()\n",
    "        self.gamma_r = relax\n",
    "        \n",
    "    # a := feature from previous decision step\n",
    "    def forward(self, a, priors): \n",
    "        a = self.BN(self.fc(a)) \n",
    "        mask = self.sparsemax(a*priors) \n",
    "        priors = priors*(self.gamma_r - mask)  #updating the prior\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "infectious-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLU(nn.Module):\n",
    "    def __init__(self, inp_dim, out_dim, fc=None, vbs=64):\n",
    "        super().__init__()\n",
    "        if fc:\n",
    "            self.fc = fc\n",
    "        else:\n",
    "            self.fc = nn.Linear(inp_dim, out_dim*2)\n",
    "        self.BN = GhostBatchNorm(out_dim*2, vbs=vbs) \n",
    "        self.od = out_dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.BN(self.fc(x))\n",
    "        return x[:, :self.od]*torch.sigmoid(x[:, self.od:])\n",
    "    \n",
    "class FeatTransformer(nn.Module):\n",
    "    def __init__(self, inp_dim, out_dim, shared, n_ind, vbs=64):\n",
    "        super().__init__()\n",
    "        first = True\n",
    "        self.shared = nn.ModuleList()\n",
    "        if shared:\n",
    "            self.shared.append(GLU(inp_dim, out_dim, shared[0], vbs=vbs))\n",
    "            first= False    \n",
    "            for fc in shared[1:]:\n",
    "                self.shared.append(GLU(out_dim, out_dim, fc, vbs=vbs))\n",
    "        else:\n",
    "            self.shared = None\n",
    "        self.independ = nn.ModuleList()\n",
    "        if first:\n",
    "            self.independ.append(GLU(inp, out_dim, vbs=vbs))\n",
    "        for x in range(first, n_ind):\n",
    "            self.independ.append(GLU(out_dim, out_dim, vbs=vbs))\n",
    "        device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.scale = torch.sqrt(torch.tensor([.5], device=device))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.shared:\n",
    "            x = self.shared[0](x)\n",
    "            for glu in self.shared[1:]:\n",
    "                x = torch.add(x, glu(x))\n",
    "                x = x*self.scale\n",
    "        for glu in self.independ:\n",
    "            x = torch.add(x, glu(x))\n",
    "            x = x*self.scale\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "adequate-dallas",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionStep(nn.Module):\n",
    "    def __init__(self, inp_dim, n_d, n_a, shared, n_ind, relax, vbs=64):\n",
    "        super().__init__()\n",
    "        self.feat_transformer = FeatTransformer(inp_dim, n_d + n_a, shared, n_ind, vbs)\n",
    "        self.attn_transformer =  AttnTransformer(n_a, inp_dim, relax, vbs)\n",
    "        \n",
    "    def forward(self, x, a, priors):\n",
    "        mask = self.attn_transformer(a, priors)\n",
    "        sparse_loss = ((-1) * mask * torch.log(mask + 1e-10)).mean()\n",
    "        x = self.feat_transformer(x * mask)\n",
    "        return x, sparse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "optical-glance",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabNet(nn.Module):\n",
    "    def __init__(self, inp_dim, final_out_dim,\n",
    "                 n_d=64, n_a=64,\n",
    "                 n_shared=2, n_ind=2,\n",
    "                 n_steps=5, relax=1.2, vbs=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        if n_shared>0:\n",
    "            self.shared = nn.ModuleList()\n",
    "            self.shared.append(nn.Linear(inp_dim, 2*(n_d + n_a)))\n",
    "            \n",
    "            for x in range(n_shared-1):\n",
    "                self.shared.append(nn.Linear(n_d + n_a, 2*(n_d + n_a)))\n",
    "        else:\n",
    "            self.shared = None\n",
    "        self.first_step = FeatTransformer(inp_dim, n_d+n_a, self.shared, n_ind) \n",
    "        self.steps = nn.ModuleList()\n",
    "        \n",
    "        for x in range(n_steps - 1):\n",
    "            self.steps.append(DecisionStep(inp_dim, n_d, n_a, self.shared, n_ind, relax, vbs))\n",
    "        \n",
    "        self.fc = nn.Linear(n_d, final_out_dim)\n",
    "        self.bn = nn.BatchNorm1d(inp_dim)\n",
    "        self.n_d = n_d\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn(x)\n",
    "        x_a = self.first_step(x)[:,self.n_d:]\n",
    "        sparse_loss = torch.zeros(1).to(x.device)\n",
    "        out = torch.zeros(x.size(0),self.n_d).to(x.device)\n",
    "        priors = torch.ones(x.shape).to(x.device)\n",
    "        for step in self.steps:\n",
    "            x_te, l = step(x,x_a,priors)\n",
    "            out += F.relu(x_te[:,:self.n_d])\n",
    "            x_a = x_te[:,self.n_d:]\n",
    "            sparse_loss += l\n",
    "        return self.fc(out), sparse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "earned-criticism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4.3863e-01, -5.7510e-01],\n",
       "         [-3.5529e-01, -5.2496e-01],\n",
       "         [-4.1787e-01, -5.9366e-01],\n",
       "         [ 2.0010e-01, -9.9658e-01],\n",
       "         [ 6.0293e-01, -6.2393e-01],\n",
       "         [-1.9921e-01, -2.7227e-01],\n",
       "         [-1.4657e-01, -1.3763e-01],\n",
       "         [ 1.0933e-01, -4.4406e-01],\n",
       "         [ 5.9519e-01, -1.4738e+00],\n",
       "         [ 4.8816e-01, -8.5086e-01],\n",
       "         [-6.8618e-02, -6.8230e-01],\n",
       "         [ 7.9431e-01, -1.6560e+00],\n",
       "         [-5.2185e-01, -7.0093e-01],\n",
       "         [-5.5549e-01, -3.9888e-01],\n",
       "         [-3.0898e-01, -3.9262e-01],\n",
       "         [-5.7943e-01, -4.5116e-01],\n",
       "         [-2.3193e-01, -1.1476e+00],\n",
       "         [ 5.2778e-01, -7.2030e-01],\n",
       "         [ 2.2045e-01, -4.8974e-01],\n",
       "         [ 5.2555e-02, -2.8357e-01],\n",
       "         [-4.4630e-01, -3.1710e-01],\n",
       "         [-1.5227e-01, -2.6660e-01],\n",
       "         [-1.7841e-02, -4.4746e-01],\n",
       "         [-2.3321e-01, -9.1761e-01],\n",
       "         [ 4.4332e-01, -9.1119e-01],\n",
       "         [-9.2041e-01, -1.0135e+00],\n",
       "         [ 2.2039e-01, -7.0681e-01],\n",
       "         [-4.8339e-01, -7.0009e-02],\n",
       "         [-5.9144e-01, -4.3732e-01],\n",
       "         [ 5.0052e-01, -1.1202e+00],\n",
       "         [ 4.4871e-01, -1.4142e+00],\n",
       "         [ 2.5954e-01, -4.1234e-01],\n",
       "         [-6.0780e-01, -7.4666e-01],\n",
       "         [ 5.4490e-02, -3.4109e-01],\n",
       "         [ 2.2324e-01, -4.1101e-01],\n",
       "         [ 1.8106e-01, -9.7992e-01],\n",
       "         [-5.0571e-01, -1.3488e-01],\n",
       "         [-3.7272e-01, -1.5540e+00],\n",
       "         [-1.8696e-01, -4.1465e-01],\n",
       "         [ 1.6063e-01, -6.4300e-01],\n",
       "         [-3.9653e-01, -5.5855e-01],\n",
       "         [ 2.0048e-01, -3.4990e-01],\n",
       "         [-3.6583e-01, -3.1470e-01],\n",
       "         [-1.9997e-01, -5.5459e-01],\n",
       "         [ 5.3120e-01, -1.0825e+00],\n",
       "         [-8.7960e-02, -7.9468e-01],\n",
       "         [-2.4458e-01, -2.2768e-01],\n",
       "         [ 3.3060e-01, -4.5995e-01],\n",
       "         [ 6.8523e-01, -9.6950e-01],\n",
       "         [ 4.9288e-01, -9.6576e-01],\n",
       "         [-3.3220e-01, -8.5036e-01],\n",
       "         [-4.2616e-01, -3.7285e-01],\n",
       "         [-5.1537e-01, -2.6581e-01],\n",
       "         [-2.9423e-01, -2.0221e+00],\n",
       "         [ 3.6990e-01, -5.1695e-01],\n",
       "         [-2.8197e-01, -1.2048e+00],\n",
       "         [ 3.4706e-01, -8.7943e-01],\n",
       "         [-4.0114e-01, -8.2954e-01],\n",
       "         [-3.7490e-01, -4.1994e-01],\n",
       "         [-6.3207e-01, -1.7420e+00],\n",
       "         [ 4.5078e-01, -1.7261e-01],\n",
       "         [ 7.9468e-01, -1.3991e+00],\n",
       "         [ 2.2380e-01, -1.5610e+00],\n",
       "         [-6.9099e-01, -7.8822e-01],\n",
       "         [ 3.9969e-02, -3.9350e-01],\n",
       "         [-8.2891e-02, -7.6576e-01],\n",
       "         [ 4.3977e-01, -6.7481e-01],\n",
       "         [-2.3790e-01, -2.4334e-01],\n",
       "         [-5.8425e-01, -4.1613e-01],\n",
       "         [-4.8907e-01, -3.7042e-01],\n",
       "         [-4.1704e-01, -5.0756e-01],\n",
       "         [-5.8828e-01, -3.4654e-01],\n",
       "         [-2.0195e-01, -5.6317e-01],\n",
       "         [ 3.5885e-02, -4.2949e-02],\n",
       "         [-1.6426e-01, -2.2124e-01],\n",
       "         [ 8.0249e-01, -1.7563e+00],\n",
       "         [ 3.7222e-02, -1.1245e+00],\n",
       "         [ 6.7165e-02, -7.9633e-01],\n",
       "         [ 4.2731e-01, -4.7943e-01],\n",
       "         [ 8.5460e-03, -5.3247e-01],\n",
       "         [-3.6402e-04, -3.4777e-01],\n",
       "         [-3.6691e-01, -1.3094e-01],\n",
       "         [ 1.4505e-01, -6.1929e-01],\n",
       "         [-6.1413e-02, -2.5176e-01],\n",
       "         [ 3.8467e-01, -1.6116e+00],\n",
       "         [-3.5605e-01, -8.5716e-01],\n",
       "         [ 1.6439e-01, -1.4050e+00],\n",
       "         [-1.6677e-01, -4.3870e-01],\n",
       "         [-4.7783e-02, -3.0099e-01],\n",
       "         [ 3.1766e-01, -1.6901e+00],\n",
       "         [-3.8590e-01, -6.0709e-01],\n",
       "         [ 2.9551e-01, -4.4072e-01],\n",
       "         [ 7.8290e-02, -4.7787e-01],\n",
       "         [ 4.4706e-01, -6.5862e-01],\n",
       "         [ 1.4198e-01, -3.8896e-01],\n",
       "         [ 1.1583e-03, -3.2231e-01],\n",
       "         [ 4.7954e-01, -5.9027e-01],\n",
       "         [ 1.6480e-01, -4.7729e-01],\n",
       "         [-4.8786e-01, -1.4390e+00],\n",
       "         [-1.8343e-01, -5.8272e-01]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
       " tensor([0.6653], device='cuda:0', grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TabNet(3, 2).to(torch.device('cuda'))\n",
    "model(c.to(torch.device('cuda'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "still-formula",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to train:\n",
    "# critrion = nn.BCELoss()\n",
    "# model.train()\n",
    "# optimizer = optim.Adam(model.parameters(),lr=0.007809719000164987,weight_decay=0.00001)\n",
    "# # sched = optim.lr_scheduler.ReduceLROnPlateau(optimizer,factor=0.1,patience=3,verbose=True)\n",
    "# for i, tar in train_loader:\n",
    "#     out, l = model(...)\n",
    "#     optimizer.zero_grad()\n",
    "#     loss = critrion(out, tar.to(device)) + l*sparse_constant\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     # sched.step(losses[-1]) # if on val set \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
